<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="mobile-web-app-capable" content="yes">
    <title>
        Projecting Your Data - HackMD
    </title>
    <link rel="icon" type="image/png" href="https://hackmd.io/favicon.png">
    <link rel="apple-touch-icon" href="https://hackmd.io/apple-touch-icon.png">

    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha256-eZrrJcwDc/3uDhsdt61sL2oOBY362qM3lon1gyExkL0=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/ionicons/2.0.1/css/ionicons.min.css" integrity="sha256-3iu9jgsy9TpTwXKb7bNQzqWekRX7pPK+2OLj3R922fo=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/octicons/3.5.0/octicons.min.css" integrity="sha256-QiWfLIsCT02Sdwkogf6YMiQlj4NE84MKkzEMkZnMGdg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.5.1/themes/prism.min.css" integrity="sha256-vtR0hSWRc3Tb26iuN2oZHt3KRUomwTufNIf5/4oeCyg=" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@hackmd/emojify.js@2.1.0/dist/css/basic/emojify.min.css" integrity="sha256-UOrvMOsSDSrW6szVLe8ZDZezBxh5IoIfgTwdNDgTjiU=" crossorigin="anonymous" />
    <style>
        @import url(https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,500,500i|Source+Code+Pro:300,400,500|Source+Sans+Pro:300,300i,400,400i,600,600i|Source+Serif+Pro&subset=latin-ext);.hljs{display:block;background:#fff;padding:.5em;color:#333;overflow-x:auto}.hljs-comment,.hljs-meta{color:#969896}.hljs-emphasis,.hljs-quote,.hljs-string,.hljs-strong,.hljs-template-variable,.hljs-variable{color:#df5000}.hljs-keyword,.hljs-selector-tag,.hljs-type{color:#a71d5d}.hljs-attribute,.hljs-bullet,.hljs-literal,.hljs-number,.hljs-symbol{color:#0086b3}.hljs-built_in,.hljs-builtin-name{color:#005cc5}.hljs-name,.hljs-section{color:#63a35c}.hljs-tag{color:#333}.hljs-attr,.hljs-selector-attr,.hljs-selector-class,.hljs-selector-id,.hljs-selector-pseudo,.hljs-title{color:#795da3}.hljs-addition{color:#55a532;background-color:#eaffea}.hljs-deletion{color:#bd2c00;background-color:#ffecec}.hljs-link{text-decoration:underline}.markdown-body{font-size:16px;line-height:1.5;word-wrap:break-word}.markdown-body:after,.markdown-body:before{display:table;content:""}.markdown-body:after{clear:both}.markdown-body>:first-child{margin-top:0!important}.markdown-body>:last-child{margin-bottom:0!important}.markdown-body a:not([href]){color:inherit;text-decoration:none}.markdown-body .absent{color:#c00}.markdown-body .anchor{float:left;padding-right:4px;margin-left:-20px;line-height:1}.markdown-body .anchor:focus{outline:none}.markdown-body blockquote,.markdown-body dl,.markdown-body ol,.markdown-body p,.markdown-body pre,.markdown-body table,.markdown-body ul{margin-top:0;margin-bottom:16px}.markdown-body hr{height:.25em;padding:0;margin:24px 0;background-color:#e7e7e7;border:0}.markdown-body blockquote{font-size:16px;padding:0 1em;color:#777;border-left:.25em solid #ddd}.markdown-body blockquote>:first-child{margin-top:0}.markdown-body blockquote>:last-child{margin-bottom:0}.markdown-body kbd,.popover kbd{display:inline-block;padding:3px 5px;font-size:11px;line-height:10px;color:#555;vertical-align:middle;background-color:#fcfcfc;border:1px solid #ccc;border-bottom-color:#bbb;border-radius:3px;box-shadow:inset 0 -1px 0 #bbb}.markdown-body .loweralpha{list-style-type:lower-alpha}.markdown-body h1,.markdown-body h2,.markdown-body h3,.markdown-body h4,.markdown-body h5,.markdown-body h6{margin-top:24px;margin-bottom:16px;font-weight:600;line-height:1.25}.markdown-body h1 .octicon-link,.markdown-body h2 .octicon-link,.markdown-body h3 .octicon-link,.markdown-body h4 .octicon-link,.markdown-body h5 .octicon-link,.markdown-body h6 .octicon-link{color:#000;vertical-align:middle;visibility:hidden}.markdown-body h1:hover .anchor,.markdown-body h2:hover .anchor,.markdown-body h3:hover .anchor,.markdown-body h4:hover .anchor,.markdown-body h5:hover .anchor,.markdown-body h6:hover .anchor{text-decoration:none}.markdown-body h1:hover .anchor .octicon-link,.markdown-body h2:hover .anchor .octicon-link,.markdown-body h3:hover .anchor .octicon-link,.markdown-body h4:hover .anchor .octicon-link,.markdown-body h5:hover .anchor .octicon-link,.markdown-body h6:hover .anchor .octicon-link{visibility:visible}.markdown-body h1 code,.markdown-body h1 tt,.markdown-body h2 code,.markdown-body h2 tt,.markdown-body h3 code,.markdown-body h3 tt,.markdown-body h4 code,.markdown-body h4 tt,.markdown-body h5 code,.markdown-body h5 tt,.markdown-body h6 code,.markdown-body h6 tt{font-size:inherit}.markdown-body h1{font-size:2em}.markdown-body h1,.markdown-body h2{padding-bottom:.3em;border-bottom:1px solid #eee}.markdown-body h2{font-size:1.5em}.markdown-body h3{font-size:1.25em}.markdown-body h4{font-size:1em}.markdown-body h5{font-size:.875em}.markdown-body h6{font-size:.85em;color:#777}.markdown-body ol,.markdown-body ul{padding-left:2em}.markdown-body ol.no-list,.markdown-body ul.no-list{padding:0;list-style-type:none}.markdown-body ol ol,.markdown-body ol ul,.markdown-body ul ol,.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li>p{margin-top:16px}.markdown-body li+li{padding-top:.25em}.markdown-body dl{padding:0}.markdown-body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}.markdown-body dl dd{padding:0 16px;margin-bottom:16px}.markdown-body table{display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}.markdown-body table th{font-weight:700}.markdown-body table td,.markdown-body table th{padding:6px 13px;border:1px solid #ddd}.markdown-body table tr{background-color:#fff;border-top:1px solid #ccc}.markdown-body table tr:nth-child(2n){background-color:#f8f8f8}.markdown-body img{max-width:100%;box-sizing:content-box;background-color:#fff}.markdown-body img[align=right]{padding-left:20px}.markdown-body img[align=left]{padding-right:20px}.markdown-body .emoji{max-width:none;vertical-align:text-top;background-color:transparent}.markdown-body span.frame{display:block;overflow:hidden}.markdown-body span.frame>span{display:block;float:left;width:auto;padding:7px;margin:13px 0 0;overflow:hidden;border:1px solid #ddd}.markdown-body span.frame span img{display:block;float:left}.markdown-body span.frame span span{display:block;padding:5px 0 0;clear:both;color:#333}.markdown-body span.align-center{display:block;overflow:hidden;clear:both}.markdown-body span.align-center>span{display:block;margin:13px auto 0;overflow:hidden;text-align:center}.markdown-body span.align-center span img{margin:0 auto;text-align:center}.markdown-body span.align-right{display:block;overflow:hidden;clear:both}.markdown-body span.align-right>span{display:block;margin:13px 0 0;overflow:hidden;text-align:right}.markdown-body span.align-right span img{margin:0;text-align:right}.markdown-body span.float-left{display:block;float:left;margin-right:13px;overflow:hidden}.markdown-body span.float-left span{margin:13px 0 0}.markdown-body span.float-right{display:block;float:right;margin-left:13px;overflow:hidden}.markdown-body span.float-right>span{display:block;margin:13px auto 0;overflow:hidden;text-align:right}.markdown-body code,.markdown-body tt{padding:0;padding-top:.2em;padding-bottom:.2em;margin:0;font-size:85%;background-color:rgba(0,0,0,.04);border-radius:3px}.markdown-body code:after,.markdown-body code:before,.markdown-body tt:after,.markdown-body tt:before{letter-spacing:-.2em;content:"\00a0"}.markdown-body code br,.markdown-body tt br{display:none}.markdown-body del code{text-decoration:inherit}.markdown-body pre{word-wrap:normal}.markdown-body pre>code{padding:0;margin:0;font-size:100%;word-break:normal;white-space:pre;background:transparent;border:0}.markdown-body .highlight{margin-bottom:16px}.markdown-body .highlight pre{margin-bottom:0;word-break:normal}.markdown-body .highlight pre,.markdown-body pre{padding:16px;overflow:auto;font-size:85%;line-height:1.45;background-color:#f7f7f7;border-radius:3px}.markdown-body pre code,.markdown-body pre tt{display:inline;max-width:auto;padding:0;margin:0;overflow:visible;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}.markdown-body pre code:after,.markdown-body pre code:before,.markdown-body pre tt:after,.markdown-body pre tt:before{content:normal}.markdown-body .csv-data td,.markdown-body .csv-data th{padding:5px;overflow:hidden;font-size:12px;line-height:1;text-align:left;white-space:nowrap}.markdown-body .csv-data .blob-line-num{padding:10px 8px 9px;text-align:right;background:#fff;border:0}.markdown-body .csv-data tr{border-top:0}.markdown-body .csv-data th{font-weight:700;background:#f8f8f8;border-top:0}.news .alert .markdown-body blockquote{padding:0 0 0 40px;border:0 none}.activity-tab .news .alert .commits,.activity-tab .news .markdown-body blockquote{padding-left:0}.task-list-item{list-style-type:none}.task-list-item label{font-weight:400}.task-list-item.enabled label{cursor:pointer}.task-list-item+.task-list-item{margin-top:3px}.task-list-item-checkbox{float:left;margin:.31em 0 .2em -1.3em!important;vertical-align:middle;cursor:default!important}.markdown-body{padding-top:40px;padding-bottom:40px;max-width:758px;overflow:visible!important;position:relative}.markdown-body .emoji{vertical-align:top}.markdown-body pre{border:inherit!important}.markdown-body code{color:inherit!important}.markdown-body pre code .wrapper{display:-moz-inline-flex;display:-ms-inline-flex;display:-o-inline-flex;display:inline-flex}.markdown-body pre code .gutter{float:left;overflow:hidden;-webkit-user-select:none;user-select:none}.markdown-body pre code .gutter.linenumber{text-align:right;position:relative;display:inline-block;cursor:default;z-index:4;padding:0 8px 0 0;min-width:20px;box-sizing:content-box;color:#afafaf!important;border-right:3px solid #6ce26c!important}.markdown-body pre code .gutter.linenumber>span:before{content:attr(data-linenumber)}.markdown-body pre code .code{float:left;margin:0 0 0 16px}.markdown-body .gist .line-numbers{border-left:none;border-top:none;border-bottom:none}.markdown-body .gist .line-data{border:none}.markdown-body .gist table{border-spacing:0;border-collapse:inherit!important}.markdown-body code[data-gist-id]{background:none;padding:0}.markdown-body code[data-gist-id]:after,.markdown-body code[data-gist-id]:before{content:""}.markdown-body code[data-gist-id] .blob-num{border:unset}.markdown-body code[data-gist-id] table{overflow:unset;margin-bottom:unset}.markdown-body code[data-gist-id] table tr{background:unset}.markdown-body[dir=rtl] pre{direction:ltr}.markdown-body[dir=rtl] code{direction:ltr;unicode-bidi:embed}.markdown-body .alert>p:last-child{margin-bottom:0}.markdown-body pre.abc,.markdown-body pre.flow-chart,.markdown-body pre.graphviz,.markdown-body pre.mermaid,.markdown-body pre.sequence-diagram,.markdown-body pre.vega{text-align:center;background-color:inherit;border-radius:0;white-space:inherit;overflow:visible}.markdown-body pre.abc>code,.markdown-body pre.flow-chart>code,.markdown-body pre.graphviz>code,.markdown-body pre.mermaid>code,.markdown-body pre.sequence-diagram>code,.markdown-body pre.vega>code{text-align:left}.markdown-body pre.abc>svg,.markdown-body pre.flow-chart>svg,.markdown-body pre.graphviz>svg,.markdown-body pre.mermaid>svg,.markdown-body pre.sequence-diagram>svg,.markdown-body pre.vega>svg{max-width:100%;height:100%}.markdown-body pre>code.wrap{white-space:pre-wrap;white-space:-moz-pre-wrap;white-space:-pre-wrap;white-space:-o-pre-wrap;word-wrap:break-word}.markdown-body .alert>p:last-child,.markdown-body .alert>ul:last-child{margin-bottom:0}.markdown-body summary{display:list-item}.markdown-body summary:focus{outline:none}.markdown-body details summary{cursor:pointer}.markdown-body details:not([open])>:not(summary){display:none}.markdown-body figure{margin:1em 40px}.markdown-body .mark,.markdown-body mark{background-color:#fff1a7}.vimeo,.youtube{cursor:pointer;display:table;text-align:center;background-position:50%;background-repeat:no-repeat;background-size:contain;background-color:#000;overflow:hidden}.vimeo,.youtube{position:relative;width:100%}.youtube{padding-bottom:56.25%}.vimeo img{width:100%;object-fit:contain;z-index:0}.youtube img{object-fit:cover;z-index:0}.vimeo iframe,.youtube iframe,.youtube img{width:100%;height:100%;position:absolute;top:0;left:0}.vimeo iframe,.youtube iframe{vertical-align:middle;z-index:1}.vimeo .icon,.youtube .icon{position:absolute;height:auto;width:auto;top:50%;left:50%;transform:translate(-50%,-50%);color:#fff;opacity:.3;transition:opacity .2s;z-index:0}.vimeo:hover .icon,.youtube:hover .icon{opacity:.6;transition:opacity .2s}.slideshare .inner,.speakerdeck .inner{position:relative;width:100%}.slideshare .inner iframe,.speakerdeck .inner iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%}.figma{display:table;position:relative;width:100%;padding-bottom:56.25%}.figma iframe{position:absolute;top:0;bottom:0;left:0;right:0;width:100%;height:100%;border:1px solid #eee}.MJX_Assistive_MathML{display:none}#MathJax_Message{z-index:1000!important}.ui-infobar{position:relative;z-index:2;max-width:760px;margin:25px auto -25px;color:#777}.toc .invisable-node{list-style-type:none}.ui-toc{position:fixed;bottom:20px;z-index:998}.ui-toc.both-mode{margin-left:8px}.ui-toc.both-mode .ui-toc-label{height:40px;padding:10px 4px;border-top-left-radius:0;border-bottom-left-radius:0}.ui-toc-label{background-color:#e6e6e6;border:none;color:#868686;transition:opacity .2s}.ui-toc .open .ui-toc-label{opacity:1;color:#fff;transition:opacity .2s}.ui-toc-label:focus{opacity:.3;background-color:#ccc;color:#000}.ui-toc-label:hover{opacity:1;background-color:#ccc;transition:opacity .2s}.ui-toc-dropdown{margin-top:20px;margin-bottom:20px;padding-left:10px;padding-right:10px;max-width:45vw;width:25vw;max-height:70vh;overflow:auto;text-align:inherit}.ui-toc-dropdown>.toc{max-height:calc(70vh - 100px);overflow:auto}.ui-toc-dropdown[dir=rtl] .nav{padding-right:0;letter-spacing:.0029em}.ui-toc-dropdown a{overflow:hidden;text-overflow:ellipsis;white-space:pre}.ui-toc-dropdown .nav>li>a{display:block;padding:4px 20px;font-size:13px;font-weight:500;color:#767676}.ui-toc-dropdown .nav>li:first-child:last-child>ul,.ui-toc-dropdown .toc.expand ul{display:block}.ui-toc-dropdown .nav>li>a:focus,.ui-toc-dropdown .nav>li>a:hover{padding-left:19px;color:#000;text-decoration:none;background-color:transparent;border-left:1px solid #000}.ui-toc-dropdown[dir=rtl] .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav>li>a:hover{padding-right:19px;border-left:none;border-right:1px solid #000}.ui-toc-dropdown .nav>.active:focus>a,.ui-toc-dropdown .nav>.active:hover>a,.ui-toc-dropdown .nav>.active>a{padding-left:18px;font-weight:700;color:#000;background-color:transparent;border-left:2px solid #000}.ui-toc-dropdown[dir=rtl] .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav>.active>a{padding-right:18px;border-left:none;border-right:2px solid #000}.ui-toc-dropdown .nav .nav{display:none;padding-bottom:10px}.ui-toc-dropdown .nav>.active>ul{display:block}.ui-toc-dropdown .nav .nav>li>a{padding-top:1px;padding-bottom:1px;padding-left:30px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a{padding-right:30px}.ui-toc-dropdown .nav .nav>li>ul>li>a{padding-top:1px;padding-bottom:1px;padding-left:40px;font-size:12px;font-weight:400}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a{padding-right:40px}.ui-toc-dropdown .nav .nav>li>a:focus,.ui-toc-dropdown .nav .nav>li>a:hover{padding-left:29px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>a:hover{padding-right:29px}.ui-toc-dropdown .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown .nav .nav>li>ul>li>a:hover{padding-left:39px}.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:focus,.ui-toc-dropdown[dir=rtl] .nav .nav>li>ul>li>a:hover{padding-right:39px}.ui-toc-dropdown .nav .nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>a{padding-left:28px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>a{padding-right:28px}.ui-toc-dropdown .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown .nav .nav>.active>.nav>.active>a{padding-left:38px;font-weight:500}.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:focus>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active:hover>a,.ui-toc-dropdown[dir=rtl] .nav .nav>.active>.nav>.active>a{padding-right:38px}.markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,sans-serif}html[lang^=ja] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .markdown-body{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html .markdown-body[lang^=ja]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html .markdown-body[lang=zh-tw]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html .markdown-body[lang=zh-cn]{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Helvetica Neue,Helvetica,Roboto,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}html[lang^=ja] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html[lang=zh-tw] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html[lang=zh-cn] .ui-toc-dropdown{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}html .ui-toc-dropdown[lang^=ja]{font-family:Source Sans Pro,Helvetica,Arial,Meiryo UI,MS PGothic,ＭＳ\ Ｐゴシック,sans-serif}html .ui-toc-dropdown[lang=zh-tw]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft JhengHei UI,微軟正黑UI,sans-serif}html .ui-toc-dropdown[lang=zh-cn]{font-family:Source Sans Pro,Helvetica,Arial,Microsoft YaHei UI,微软雅黑UI,sans-serif}.ui-affix-toc{position:fixed;top:0;max-width:15vw;max-height:70vh;overflow:auto}.back-to-top,.expand-toggle,.go-to-bottom{display:block;padding:4px 10px;margin-top:10px;margin-left:10px;font-size:12px;font-weight:500;color:#999}.back-to-top:focus,.back-to-top:hover,.expand-toggle:focus,.expand-toggle:hover,.go-to-bottom:focus,.go-to-bottom:hover{color:#563d7c;text-decoration:none}.back-to-top,.go-to-bottom{margin-top:0}.ui-user-icon{width:20px;height:20px;display:block;border-radius:50%;margin-top:2px;margin-bottom:2px;margin-right:5px;background-position:50%;background-repeat:no-repeat;background-size:cover}.ui-user-icon.small{width:18px;height:18px;display:inline-block;vertical-align:middle;margin:0 0 .2em}.ui-infobar>small>span{line-height:22px}.ui-infobar>small .dropdown{display:inline-block}.ui-infobar>small .dropdown a:focus,.ui-infobar>small .dropdown a:hover{text-decoration:none}.ui-more-info{color:#888;cursor:pointer;vertical-align:middle}.ui-more-info .fa{font-size:16px}.ui-connectedGithub,.ui-published-note{color:#888}.ui-connectedGithub{line-height:23px;white-space:nowrap}.ui-connectedGithub a.file-path{color:#888;text-decoration:none;padding-left:22px}.ui-connectedGithub a.file-path:active,.ui-connectedGithub a.file-path:hover{color:#888;text-decoration:underline}.ui-connectedGithub .fa{font-size:20px}.ui-published-note .fa{font-size:20px;vertical-align:top}.unselectable{-webkit-user-select:none;-o-user-select:none;user-select:none}.selectable{-webkit-user-select:text;-o-user-select:text;user-select:text}@media print{blockquote,div,img,pre,table{page-break-inside:avoid!important}a[href]:after{font-size:12px!important}}.markdown-body.slides{position:relative;z-index:1;color:#222}.markdown-body.slides:before{content:"";display:block;position:absolute;top:0;left:0;right:0;bottom:0;z-index:-1;background-color:currentColor;box-shadow:0 0 0 50vw}.markdown-body.slides section[data-markdown]{position:relative;margin-bottom:1.5em;background-color:#fff;text-align:center}.markdown-body.slides section[data-markdown] code{text-align:left}.markdown-body.slides section[data-markdown]:before{content:"";display:block;padding-bottom:56.23%}.markdown-body.slides section[data-markdown]>div:first-child{position:absolute;top:50%;left:1em;right:1em;transform:translateY(-50%);max-height:100%;overflow:hidden}.markdown-body.slides section[data-markdown]>ul{display:inline-block}.markdown-body.slides>section>section+section:after{content:"";position:absolute;top:-1.5em;right:1em;height:1.5em;border:3px solid #777}.site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] .site-ui-font{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}body{font-smoothing:subpixel-antialiased!important;-webkit-font-smoothing:subpixel-antialiased!important;-moz-osx-font-smoothing:auto!important;text-shadow:0 0 1em transparent,1px 1px 1.2px rgba(0,0,0,.004);-webkit-overflow-scrolling:touch;letter-spacing:.025em;font-family:Source Sans Pro,Helvetica,Arial,sans-serif}html[lang^=ja] body{font-family:Source Sans Pro,Helvetica,Arial,Hiragino Kaku Gothic Pro,ヒラギノ角ゴ Pro W3,Osaka,Meiryo,メイリオ,MS Gothic,ＭＳ\ ゴシック,sans-serif}html[lang=zh-tw] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang TC,Microsoft JhengHei,微軟正黑,sans-serif}html[lang=zh-cn] body{font-family:Source Sans Pro,Helvetica,Arial,PingFang SC,Microsoft YaHei,微软雅黑,sans-serif}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}abbr[data-original-title],abbr[title]{cursor:help}body.modal-open{overflow-y:auto;padding-right:0!important}
    </style>
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv.min.js" integrity="sha256-3Jy/GbSLrg0o9y5Z5n1uw0qxZECH7C6OQpVBgNFYa0g=" crossorigin="anonymous"></script>
    	<script src="https://cdnjs.cloudflare.com/ajax/libs/respond.js/1.4.2/respond.min.js" integrity="sha256-g6iAfvZp+nDQ2TdTR/VVKJf3bGro4ub5fvWSWVRi2NE=" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/es5-shim/4.5.9/es5-shim.min.js" integrity="sha256-8E4Is26QH0bD52WoQpcB+R/tcWQtpzlCojrybUd7Mxo=" crossorigin="anonymous"></script>
    <![endif]-->
</head>

<body>
    <div id="doc" class="markdown-body container-fluid comment-enabled" data-hard-breaks="false"><h1 id="Projecting-Your-Data" data-id="Projecting-Your-Data"><a class="anchor hidden-xs" href="#Projecting-Your-Data" title="Projecting-Your-Data"><span class="octicon octicon-link"></span></a><span>Projecting Your Data</span></h1><p><img src="https://i.imgur.com/69GOnM9.gif" alt="" loading="lazy"></p><p><span>In this assignment, we will use Pytorch to implement a Convolutional Neural Network (CNN) classifier for the MNIST datasets and discusses how to use Pytorch to build a neural network model from scratch for a custom dataset. After finishing the classifier, we will build an embedding projector based on the model to observe the model’s behavior on the dataset. This assignment will combine the concepts including classification, convolution neural network, and working with embeddings.</span></p><p><span>Different hyperparameters or model architectures can lead to different outputs on the same dataset, and different dimensionality reduction algorithms can change the way we project the embeddings into a 2D or 3D space, which in turn affects the way we interpret the model. After building the embedding projector, we will explore how the projection of the embeddings changes under different settings and analyze the behavior of the model.</span></p><p><span>This assignment is organized as follows:</span></p><ul>
<li><span>Part A. Data exploration</span></li>
<li><span>Part B. Building the classifier</span></li>
<li><span>Part C. Building the embedding projector</span></li>
<li><span>Part D. Analyzing the embeddings</span></li>
</ul><p><span>Much of this assignment is inspired by Google’s embedding projector </span><a href="#References"><span>[1]</span></a><span>, and we will explore how to make and improve our own embedding projector based on our needs.</span></p><h2 id="Part-A-Data-exploration" data-id="Part-A-Data-exploration"><a class="anchor hidden-xs" href="#Part-A-Data-exploration" title="Part-A-Data-exploration"><span class="octicon octicon-link"></span></a><span>Part A. Data exploration</span></h2><h3 id="MNIST-Dataset" data-id="MNIST-Dataset"><a class="anchor hidden-xs" href="#MNIST-Dataset" title="MNIST-Dataset"><span class="octicon octicon-link"></span></a><span>MNIST Dataset</span></h3><p><span>The MNIST dataset is an acronym that stands for the Modified National Institute of Standards and Technology dataset. It is a dataset of 60,000 small square 28×28 pixel grayscale images of handwritten single digits between 0 and 9.</span></p><p><img src="https://i.imgur.com/gE3EESR.png" alt="" loading="lazy"></p><h3 id="Part-A1---Load-Dataset-3-pt" data-id="Part-A1---Load-Dataset-3-pt"><a class="anchor hidden-xs" href="#Part-A1---Load-Dataset-3-pt" title="Part-A1---Load-Dataset-3-pt"><span class="octicon octicon-link"></span></a><span>Part A.1 - Load Dataset [3 pt]</span></h3><p><span>A package called torchvision, that has data loaders for common datasets such as MNIST, Imagenet, CIFAR10, etc. For the following example, we will use the MNIST dataset. It has </span><span class="ui-comment-inline-span"><span class="ui-comment-inline-span">t</span></span><span>en classes: 0, 1, 2, 3, 4, 5, 6, 7, 8, 9. The images in MNIST are of size 1x28x28, i.e. 1-channel images of 28x28 pixels in size.</span></p><p><span>Run the following example to load the dataset:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torchvision
<span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms

<span class="hljs-comment"># The output of torchvision datasets are PILImage images of range [0, 1]. </span>
<span class="hljs-comment"># We transform them to Tensors of normalized range [-1, 1].</span>
transform = transforms.Compose([
    transforms.ToTensor(),
])

trainset = torchvision.datasets.MNIST(root=<span class="hljs-string">'./data'</span>, train=<span class="hljs-literal">True</span>,
                                        download=<span class="hljs-literal">True</span>, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, <span class="hljs-comment"># TODO</span>
                                          shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>) 

testset = torchvision.datasets.MNIST(root=<span class="hljs-string">'./data'</span>, train=<span class="hljs-literal">False</span>,
                                       download=<span class="hljs-literal">True</span>, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, <span class="hljs-comment"># TODO</span>
                                         shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">2</span>)

classes = (<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span> , <span class="hljs-number">8</span>, <span class="hljs-number">9</span>)
</code></pre><h4 id="Explain-why-the-training-dataset-needs-to-be-shuffled-and-the-testing-dataset-does-not" data-id="Explain-why-the-training-dataset-needs-to-be-shuffled-and-the-testing-dataset-does-not"><a class="anchor hidden-xs" href="#Explain-why-the-training-dataset-needs-to-be-shuffled-and-the-testing-dataset-does-not" title="Explain-why-the-training-dataset-needs-to-be-shuffled-and-the-testing-dataset-does-not"><span class="octicon octicon-link"></span></a><span>Explain why the training dataset needs to be shuffled and the testing dataset does not.</span></h4><h3 id="Part-A2---Preview-the-Dataset-2-pt" data-id="Part-A2---Preview-the-Dataset-2-pt"><a class="anchor hidden-xs" href="#Part-A2---Preview-the-Dataset-2-pt" title="Part-A2---Preview-the-Dataset-2-pt"><span class="octicon octicon-link"></span></a><span>Part A.2 - Preview the Dataset [2 pt]</span></h3><p><span>Run the following codes to preview the dataset:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np

<span class="hljs-comment"># functions to show an image</span>


<span class="hljs-keyword">def</span> <span class="hljs-title function_">imshow</span>(<span class="hljs-params">img</span>):
    img = img / <span class="hljs-number">2</span> + <span class="hljs-number">0.5</span>     <span class="hljs-comment"># unnormalize</span>
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>)))
    plt.show()


<span class="hljs-comment"># get some random training images</span>
dataiter = <span class="hljs-built_in">iter</span>(trainloader)
images, labels = dataiter.<span class="hljs-built_in">next</span>()

<span class="hljs-comment"># show images</span>
imshow(torchvision.utils.make_grid(images))
<span class="hljs-comment"># print labels</span>
<span class="hljs-built_in">print</span>(<span class="hljs-string">' '</span>.join(<span class="hljs-string">'%5s'</span> % classes[labels[j]] <span class="hljs-keyword">for</span> j <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(batch_size)))
</code></pre><h4 data-id="" id=""></h4><h3 id="Part-A3---Build-Your-Dataset-5-pt" data-id="Part-A3---Build-Your-Dataset-5-pt"><a class="anchor hidden-xs" href="#Part-A3---Build-Your-Dataset-5-pt" title="Part-A3---Build-Your-Dataset-5-pt"><span class="octicon octicon-link"></span></a><span>Part A.3 - Build Your Dataset [5 pt]</span></h3><p><code>torch.utils.data.Dataset</code><span> is an abstract class representing a dataset. Your custom dataset should inherit Dataset and override the following methods:</span></p><ul>
<li><code>__len__</code><span> so that `len(dataset)`` returns the size of the dataset.</span></li>
<li><code>__getitem__</code><span> to support the indexing such that dataset[i] can be used to get the ith sample.</span></li>
</ul><p><span>Adjust the following codes to build your MNIST dataset:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> torch


<span class="hljs-keyword">class</span> <span class="hljs-title class_">MNIST</span>(torch.utils.data.Dataset):

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>():
    
        <span class="hljs-comment"># TODO</span>
        
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__len__</span>():
    
        <span class="hljs-comment"># TODo</span>
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__getitem__</span>(<span class="hljs-params">self, index</span>):
    
        <span class="hljs-comment"># TODO</span>

</code></pre><h3 id="Part-A4---Data-Augmentation-5-pt" data-id="Part-A4---Data-Augmentation-5-pt"><a class="anchor hidden-xs" href="#Part-A4---Data-Augmentation-5-pt" title="Part-A4---Data-Augmentation-5-pt"><span class="octicon octicon-link"></span></a><span>Part A.4 - Data Augmentation [5 pt]</span></h3><p><span>Data augmentations are techniques used to increase the amount of data by adding slightly modified copies of existing data or o</span><span class="ui-comment-inline-span">ther synthetic data that we produce in the process of data augmentation.</span></p><p><span class="ui-comment-inline-span">The following example shows two different augmentation methods:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> torchvision.transforms <span class="hljs-keyword">as</span> transforms

transforms.Compose([
    transforms.RandomRotation(<span class="hljs-number">30</span>),
    transforms.RandomResizedCrop(<span class="hljs-number">28</span>),
])
</code></pre><h4 id="Explain-your-choice-from-Pytorch’s-transformations-2-and-why" data-id="Explain-your-choice-from-Pytorch’s-transformations-2-and-why"><a class="anchor hidden-xs" href="#Explain-your-choice-from-Pytorch’s-transformations-2-and-why" title="Explain-your-choice-from-Pytorch’s-transformations-2-and-why"><span class="octicon octicon-link"></span></a><span class="ui-comment-inline-span">Explain your choice from Pytorch’s transformations </span><a href="#References"><span class="ui-comment-inline-span">[2]</span></a><span class="ui-comment-inline-span"> and why</span><span>.</span></h4><h2 id="Part-B-Building-the-classifier" data-id="Part-B-Building-the-classifier"><a class="anchor hidden-xs" href="#Part-B-Building-the-classifier" title="Part-B-Building-the-classifier"><span class="octicon octicon-link"></span></a><span>Part B. Building the classifier</span></h2><h3 id="Part-B1---Define-a-Convolutional-Neural-Network-5-pt" data-id="Part-B1---Define-a-Convolutional-Neural-Network-5-pt"><a class="anchor hidden-xs" href="#Part-B1---Define-a-Convolutional-Neural-Network-5-pt" title="Part-B1---Define-a-Convolutional-Neural-Network-5-pt"><span class="octicon octicon-link"></span></a><span>Part B.1 - Define a Convolutional Neural Network [5 pt]</span></h3><p><span>Build a convolutional neural network that takes the </span><span class="ui-comment-inline-span">(1x28x28)</span><span> images as input and outputs a 10-dimensional vector to indicate the relative po</span><span class="ui-comment-inline-span">ssibilities of the ten classes</span><span>. Your model should be a subclass of nn.Module.</span></p><p><span>Following is an example:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F


<span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(nn.Module):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-built_in">super</span>(Net, self).__init__()
        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">10</span>, kernel_size=<span class="hljs-number">5</span>)
        self.conv2 = nn.Conv2d(<span class="hljs-number">10</span>, <span class="hljs-number">20</span>, kernel_size=<span class="hljs-number">5</span>)
        self.conv2_drop = nn.Dropout2d()
        self.fc1 = nn.Linear(<span class="hljs-number">320</span>, <span class="hljs-number">50</span>)
        self.fc2 = nn.Linear(<span class="hljs-number">50</span>, <span class="hljs-number">10</span>)

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):
        x = F.relu(F.max_pool2d(self.conv1(x), <span class="hljs-number">2</span>))
        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), <span class="hljs-number">2</span>))
        x = x.view(-<span class="hljs-number">1</span>, <span class="hljs-number">320</span>)
        x = F.relu(self.fc1(x))
        x = F.dropout(x, training=self.training)
        x = self.fc2(x)
        <span class="hljs-keyword">return</span> F.log_softmax(x)


net = Net()
</code></pre><h4 id="Explain-your-choice-of-neural-network-architecture" data-id="Explain-your-choice-of-neural-network-architecture"><a class="anchor hidden-xs" href="#Explain-your-choice-of-neural-network-architecture" title="Explain-your-choice-of-neural-network-architecture"><span class="octicon octicon-link"></span></a><span>Explain your choice of neural network architecture:</span></h4><ul>
<li><span>Try to change the number of convolutional layers in the forward step, and observe the resulting classification qualities. What is the number of convolutional layers that seem t</span><span class="ui-comment-inline-span">o offer the best performance?</span></li>
<li><span>What types of layers, i.e., conv1, conv2, or a differe</span><span class="ui-comment-inline-span"><span class="ui-comment-inline-span">nt design of yours, did you use?</span></span></li>
</ul><h3 id="Part-B2---Define-a-Loss-function-and-optimizer-3-pt" data-id="Part-B2---Define-a-Loss-function-and-optimizer-3-pt"><a class="anchor hidden-xs" href="#Part-B2---Define-a-Loss-function-and-optimizer-3-pt" title="Part-B2---Define-a-Loss-function-and-optimizer-3-pt"><span class="octicon octicon-link"></span></a><span>Part B.2 - Define a Loss function and optimizer [3 pt]</span></h3><h4 id="Loss-Function" data-id="Loss-Function"><a class="anchor hidden-xs" href="#Loss-Function" title="Loss-Function"><span class="octicon octicon-link"></span></a><span>Loss Function</span></h4><p><span>A loss function or cost function is a function that maps an event or values of one or more variables onto a real number, intuitively representing some “cost” associated with the event. An optimization problem seeks to minimize</span><span class="ui-comment-inline-span"> the loss/cost</span><span> - </span><a href="https://en.wikipedia.org/wiki/Loss_function" target="_blank" rel="noopener"><span>Wikipedia</span></a><span>.</span></p><p><span>Pytorch offers different loss functions for various purposes </span><a href="#References"><span>[3]</span></a><span>.</span></p><h4 id="Optimizer" data-id="Optimizer"><a class="anchor hidden-xs" href="#Optimizer" title="Optimizer"><span class="octicon octicon-link"></span></a><span>Optimizer</span></h4><p><span>O</span><span class="ui-comment-inline-span">ptimizers are software agents that employ specific algorithms to achieve the minimization goal</span><span>.</span></p><p><span>Pytorch also offers many optimization algorithms for different scenarios </span><a href="#References"><span>[4]</span></a><span>.</span></p><p><span>The fo</span><span class="ui-comment-inline-span">llowing block shows an exampl</span><span>e:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> torch.optim <span class="hljs-keyword">as</span> optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=<span class="hljs-number">0.001</span>, momentum=<span class="hljs-number">0.9</span>)
</code></pre><p><span>You may explore different combinations of loss</span><span class="ui-comment-inline-span"> functions, optimizers, and other hyperparameters based on your needs, and compare the results.</span></p><h4 id="Observe-the-performances-of-some-different-combinations-of-components-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design" data-id="Observe-the-performances-of-some-different-combinations-of-components-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design"><a class="anchor hidden-xs" href="#Observe-the-performances-of-some-different-combinations-of-components-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design" title="Observe-the-performances-of-some-different-combinations-of-components-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design"><span class="octicon octicon-link"></span></a><span>Observe the performances of some different combinations of components, and find out the best one. Are there logical relations between the classification performances and the models of your design?</span></h4><h4 id="Explain-your-choice-of-loss-function-and-optimizer" data-id="Explain-your-choice-of-loss-function-and-optimizer"><a class="anchor hidden-xs" href="#Explain-your-choice-of-loss-function-and-optimizer" title="Explain-your-choice-of-loss-function-and-optimizer"><span class="octicon octicon-link"></span></a><span class="ui-comment-inline-span">Explain your choice of loss function and optimizer.</span></h4><h4 id="Observe-the-performances-of-some-different-combinations-of-optimizer-and-loss-function-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design" data-id="Observe-the-performances-of-some-different-combinations-of-optimizer-and-loss-function-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design"><a class="anchor hidden-xs" href="#Observe-the-performances-of-some-different-combinations-of-optimizer-and-loss-function-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design" title="Observe-the-performances-of-some-different-combinations-of-optimizer-and-loss-function-and-find-out-the-best-one-Are-there-logical-relations-between-the-classification-performances-and-the-models-of-your-design"><span class="octicon octicon-link"></span></a><span>Observe the performances of some different combinations of optimizer and loss function, and find out the best one. Are there logical relations between the classification performances and the models of your design?</span></h4><h3 id="Part-B3---Train-the-network-2-pt" data-id="Part-B3---Train-the-network-2-pt"><a class="anchor hidden-xs" href="#Part-B3---Train-the-network-2-pt" title="Part-B3---Train-the-network-2-pt"><span class="octicon octicon-link"></span></a><span>Part B.3 - Train the network [2 pt]</span></h3><p><span>Train your first network on your training set.</span></p><p><span>Adjust the following codes to train the model:</span></p><pre><code class="python hljs"><span class="hljs-keyword">for</span> epoch <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">2</span>):  <span class="hljs-comment"># loop over the dataset multiple times</span>

    running_loss = <span class="hljs-number">0.0</span>
    <span class="hljs-keyword">for</span> i, data <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(trainloader, <span class="hljs-number">0</span>):
        
        <span class="hljs-comment"># TODO</span>

<span class="hljs-built_in">print</span>(<span class="hljs-string">'Finished Training'</span>)
</code></pre><p><span>The number of epochs is obviously an influential factor that affects the final outcome of the classification. Y</span><span class="ui-comment-inline-span">ou should try different alternatives and observe the corresponding results.</span></p><h2 id="Part-C-Building-the-embedding-projector" data-id="Part-C-Building-the-embedding-projector"><a class="anchor hidden-xs" href="#Part-C-Building-the-embedding-projector" title="Part-C-Building-the-embedding-projector"><span class="octicon octicon-link"></span></a><span>Part C. Building the embedding projector</span></h2><h3 id="Part-C1---Build-an-embedding-projector-5-pt" data-id="Part-C1---Build-an-embedding-projector-5-pt"><a class="anchor hidden-xs" href="#Part-C1---Build-an-embedding-projector-5-pt" title="Part-C1---Build-an-embedding-projector-5-pt"><span class="octicon octicon-link"></span></a><span>Part C.1 - Build an embedding projector [5 pt]</span></h3><p><span>In this assignment, we use </span><a href="https://www.tensorflow.org/tensorboard/" target="_blank" rel="noopener"><span>TensorBoard</span></a><span> as our visualization tool for projecting the embeddings.</span></p><p><span>Run the following example:</span></p><pre><code class="python hljs"><span class="hljs-keyword">import</span> keyword
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">from</span> torch.utils.tensorboard <span class="hljs-keyword">import</span> SummaryWriter

<span class="hljs-comment"># The writer will output to ./runs/ directory by default.</span>
writer = SummaryWriter()
meta = []
<span class="hljs-keyword">while</span> <span class="hljs-built_in">len</span>(meta)&lt;<span class="hljs-number">100</span>:
    meta = meta+keyword.kwlist <span class="hljs-comment"># get some strings</span>
meta = meta[:<span class="hljs-number">100</span>]

<span class="hljs-keyword">for</span> i, v <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(meta):
    meta[i] = v+<span class="hljs-built_in">str</span>(i)

label_img = torch.rand(<span class="hljs-number">100</span>, <span class="hljs-number">3</span>, <span class="hljs-number">10</span>, <span class="hljs-number">32</span>)
<span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>):
    label_img[i]*=i/<span class="hljs-number">100.0</span>

writer.add_embedding(torch.randn(<span class="hljs-number">100</span>, <span class="hljs-number">5</span>), metadata=meta, label_img=label_img)
writer.close()
</code></pre><p><span>Then navigate to your command line and execute the following command to open TensorBoard:</span></p><pre><code class="bash hljs">$ tensorboard --logdir=runs --bind_all
</code></pre><h4 id="Paste-your-results-here" data-id="Paste-your-results-here"><a class="anchor hidden-xs" href="#Paste-your-results-here" title="Paste-your-results-here"><span class="octicon octicon-link"></span></a><span>Paste your results here.</span></h4><h3 id="Part-C2---Project-the-Embeddings-5-pt" data-id="Part-C2---Project-the-Embeddings-5-pt"><a class="anchor hidden-xs" href="#Part-C2---Project-the-Embeddings-5-pt" title="Part-C2---Project-the-Embeddings-5-pt"><span class="octicon octicon-link"></span></a><span>Part C.2 - Project the Embeddings [5 pt]</span></h3><p><span>Adjust the following codes to write the embeddings to the TensorBoard:</span></p><pre><code class="pyhton hljs"><span class="hljs-attr">correct</span> = <span class="hljs-number">0</span>
<span class="hljs-attr">total</span> = <span class="hljs-number">0</span>

<span class="hljs-comment"># since we're not training, we don't need to calculate the gradients for our outputs</span>
<span class="hljs-keyword">with</span> torch.no_grad():
    for data <span class="hljs-keyword">in</span> testloader:
        images, <span class="hljs-attr">labels</span> = data
        <span class="hljs-comment"># calculate outputs by running images through the network</span>
        <span class="hljs-attr">outputs</span> = net(images)
        <span class="hljs-comment"># the class with the highest energy is what we choose as prediction</span>
        _, <span class="hljs-attr">predicted</span> = torch.max(outputs.data, <span class="hljs-number">1</span>)
        total += labels.size(<span class="hljs-number">0</span>)
        correct += (<span class="hljs-attr">predicted</span> == labels).sum().item()
        
        <span class="hljs-comment"># stack your embeddings and other data </span>
        <span class="hljs-comment"># TODO</span>

print('Accuracy of the network on the <span class="hljs-number">10000</span> test images: %d %%' % (
    <span class="hljs-number">100</span> * correct / total))
    
<span class="hljs-comment"># write the embeddings to the tensorboard</span>
<span class="hljs-comment"># TODO</span>
</code></pre><h4 id="Paste-your-results-on-TensorBoard-here" data-id="Paste-your-results-on-TensorBoard-here"><a class="anchor hidden-xs" href="#Paste-your-results-on-TensorBoard-here" title="Paste-your-results-on-TensorBoard-here"><span class="octicon octicon-link"></span></a><span class="ui-comment-inline-span">Paste your results on TensorBoard here.</span></h4><h2 id="Part-D-Analysing-the-embeddings" data-id="Part-D-Analysing-the-embeddings"><a class="anchor hidden-xs" href="#Part-D-Analysing-the-embeddings" title="Part-D-Analysing-the-embeddings"><span class="octicon octicon-link"></span></a><span>Part D. Analysing the embeddings</span></h2><h3 id="Part-D1---Analysing-the-embeddings-with-PCA---2-pts" data-id="Part-D1---Analysing-the-embeddings-with-PCA---2-pts"><a class="anchor hidden-xs" href="#Part-D1---Analysing-the-embeddings-with-PCA---2-pts" title="Part-D1---Analysing-the-embeddings-with-PCA---2-pts"><span class="octicon octicon-link"></span></a><span>Part D.1 - Analysing the embeddings with PCA - [2 pts]</span></h3><p><span>Principal component analysis finds a new coordinate system for a given dataset, trying to minimize the variance among the data from the perspective of the created new system. The first few components are usually more important for capturing the distributional characteristics of the given </span><span class="ui-comment-inline-span">dataset. Encoding the data based on the first few principal components is a common heuristic for reducing dimensionality while minimizing the loss of information about the data.</span></p><h4 id="Choose-different-combinations-of-principal-components-in-the-following-panel-the-red-box-on-the-left-hand-side-and-observe-the-distribution-of-the-data-in-the-chosen-coordinate-system" data-id="Choose-different-combinations-of-principal-components-in-the-following-panel-the-red-box-on-the-left-hand-side-and-observe-the-distribution-of-the-data-in-the-chosen-coordinate-system"><a class="anchor hidden-xs" href="#Choose-different-combinations-of-principal-components-in-the-following-panel-the-red-box-on-the-left-hand-side-and-observe-the-distribution-of-the-data-in-the-chosen-coordinate-system" title="Choose-different-combinations-of-principal-components-in-the-following-panel-the-red-box-on-the-left-hand-side-and-observe-the-distribution-of-the-data-in-the-chosen-coordinate-system"><span class="octicon octicon-link"></span></a><span>Choose different combinations of principal components in the following panel (the red box on the left-hand </span><span class="ui-comment-inline-span">side) and observe the distribution of the data in the chosen coordinate system.</span></h4><p><img src="https://i.imgur.com/9pEZV7W.png" alt="" loading="lazy"></p><p><span>Which combination of three components seems to separate the images of different classes best visually?</span></p><h4 id="Explain-the-meanings-of-variances-in-PCA-when-setting-different-principal-components" data-id="Explain-the-meanings-of-variances-in-PCA-when-setting-different-principal-components"><a class="anchor hidden-xs" href="#Explain-the-meanings-of-variances-in-PCA-when-setting-different-principal-components" title="Explain-the-meanings-of-variances-in-PCA-when-setting-different-principal-components"><span class="octicon octicon-link"></span></a><span class="ui-comment-inline-span">Explain the meanings of variances in PCA when setting different principal components.</span></h4><h3 id="Part-D2---Analysing-with-different-models-3-pts" data-id="Part-D2---Analysing-with-different-models-3-pts"><a class="anchor hidden-xs" href="#Part-D2---Analysing-with-different-models-3-pts" title="Part-D2---Analysing-with-different-models-3-pts"><span class="octicon octicon-link"></span></a><span>Part D.2 - Analysing with different models [3 pts]</span></h3><p><span>Adjust your model architecture, project the new embeddings, and compare with the results from the previous one.</span></p><p><span>Following is a sample:</span></p><pre><code class="python hljs"><span class="hljs-keyword">from</span> torchvision.models.resnet <span class="hljs-keyword">import</span> ResNet, BasicBlock, Bottleneck
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn

<span class="hljs-keyword">class</span> <span class="hljs-title class_">Net</span>(<span class="hljs-title class_ inherited__">ResNet</span>):
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):
        <span class="hljs-comment"># Based on ResNet18</span>
        <span class="hljs-built_in">super</span>(Net, self).__init__(BasicBlock, [<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>, <span class="hljs-number">2</span>], num_classes=<span class="hljs-number">10</span>) 
        self.conv1 = nn.Conv2d(<span class="hljs-number">1</span>, <span class="hljs-number">64</span>, kernel_size=<span class="hljs-number">7</span>, stride=<span class="hljs-number">1</span>, padding=<span class="hljs-number">3</span>,bias=<span class="hljs-literal">False</span>)

model = Net()
</code></pre><h2 id="Additionals" data-id="Additionals"><a class="anchor hidden-xs" href="#Additionals" title="Additionals"><span class="octicon octicon-link"></span></a><span>Additionals</span></h2><h3 id="Fashion-MNIST" data-id="Fashion-MNIST"><a class="anchor hidden-xs" href="#Fashion-MNIST" title="Fashion-MNIST"><span class="octicon octicon-link"></span></a><span>Fashion-MNIST</span></h3><p><span>Pytorch provides a variety of different and organized datasets that can be used quickly </span><a href="#References"><span>[5]</span></a><span>. Following is an example of modifying the program in A.1 from the MNIST dataset to the Fashion-MNIST dataset:</span></p><pre><code class="python hljs">transform = transforms.Compose([
    transforms.ToTensor(),
])

batch_size = <span class="hljs-number">4</span>

trainset = torchvision.datasets.FashionMNIST(root=<span class="hljs-string">'./data'</span>, train=<span class="hljs-literal">True</span>,
                                        download=<span class="hljs-literal">True</span>, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                          shuffle=<span class="hljs-literal">True</span>, num_workers=<span class="hljs-number">2</span>)

testset = torchvision.datasets.FashionMNIST(root=<span class="hljs-string">'./data'</span>, train=<span class="hljs-literal">False</span>,
                                       download=<span class="hljs-literal">True</span>, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,
                                         shuffle=<span class="hljs-literal">False</span>, num_workers=<span class="hljs-number">2</span>)

classes = [<span class="hljs-string">'T-shirt/top'</span>, <span class="hljs-string">'Trouser'</span>, <span class="hljs-string">'Pullover'</span>, <span class="hljs-string">'Dress'</span>, <span class="hljs-string">'Coat'</span>, <span class="hljs-string">'Sandal'</span>, <span class="hljs-string">'Shirt'</span>, <span class="hljs-string">'Sneaker'</span>, <span class="hljs-string">'Bag'</span>, <span class="hljs-string">'Ankle boot'</span>]

</code></pre><p><br>
<span>Retrain the model and project it to get different results than the MNIST dataset:</span></p><p><br>
<img src="https://i.imgur.com/qXX7OpT.png" alt="" loading="lazy"></p><h2 id="References" data-id="References"><a class="anchor hidden-xs" href="#References" title="References"><span class="octicon octicon-link"></span></a><span>References</span></h2><p><span>[1] D. Smilkov, N. Thorat, C. Nicholson, E. Reif, F. B. Viégas, and M. Wattenberg, “Embedding Projector: Interactive Visualization and Interpretation of Embeddings,” arXiv:1611.05469 [cs, stat], Nov. 2016, Accessed: Sep. 09, 2021. [Online]. Available: </span><a href="http://arxiv.org/abs/1611.05469" target="_blank" rel="noopener"><span>http://arxiv.org/abs/1611.05469</span></a></p><p><span>[2] Pytorch Transforms - </span><a href="https://pytorch.org/vision/stable/transforms.html" target="_blank" rel="noopener"><span>https://pytorch.org/vision/stable/transforms.html</span></a></p><p><span>[3] Pytorch Loss Functions - </span><a href="https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noopener"><span>https://pytorch.org/docs/stable/nn.html#loss-functions</span></a></p><p><span>[4] Pytorch Optimization Algorithms - </span><a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener"><span>https://pytorch.org/docs/stable/optim.html</span></a></p><p><span>[5] Pytorch Datasets - </span><a href="https://pytorch.org/vision/stable/datasets.html" target="_blank" rel="noopener"><span>https://pytorch.org/vision/stable/datasets.html</span></a></p></div>
    <div class="ui-toc dropup unselectable hidden-print" style="display:none;">
        <div class="pull-right dropdown">
            <a id="tocLabel" class="ui-toc-label btn btn-default" data-toggle="dropdown" href="#" role="button" aria-haspopup="true" aria-expanded="false" title="Table of content">
                <i class="fa fa-bars"></i>
            </a>
            <ul id="ui-toc" class="ui-toc-dropdown dropdown-menu" aria-labelledby="tocLabel">
                <div class="toc"><ul class="nav">
<li><a href="#Projecting-Your-Data" title="Projecting Your Data">Projecting Your Data</a><ul class="nav">
<li><a href="#Part-A-Data-exploration" title="Part A. Data exploration">Part A. Data exploration</a><ul class="nav">
<li><a href="#MNIST-Dataset" title="MNIST Dataset">MNIST Dataset</a></li>
<li><a href="#Part-A1---Load-Dataset-3-pt" title="Part A.1 - Load Dataset [3 pt]">Part A.1 - Load Dataset [3 pt]</a></li>
<li><a href="#Part-A2---Preview-the-Dataset-2-pt" title="Part A.2 - Preview the Dataset [2 pt]">Part A.2 - Preview the Dataset [2 pt]</a></li>
<li><a href="#Part-A3---Build-Your-Dataset-5-pt" title="Part A.3 - Build Your Dataset [5 pt]">Part A.3 - Build Your Dataset [5 pt]</a></li>
<li><a href="#Part-A4---Data-Augmentation-5-pt" title="Part A.4 - Data Augmentation [5 pt]">Part A.4 - Data Augmentation [5 pt]</a></li>
</ul>
</li>
<li><a href="#Part-B-Building-the-classifier" title="Part B. Building the classifier">Part B. Building the classifier</a><ul class="nav">
<li><a href="#Part-B1---Define-a-Convolutional-Neural-Network-5-pt" title="Part B.1 - Define a Convolutional Neural Network [5 pt]">Part B.1 - Define a Convolutional Neural Network [5 pt]</a></li>
<li><a href="#Part-B2---Define-a-Loss-function-and-optimizer-3-pt" title="Part B.2 - Define a Loss function and optimizer [3 pt]">Part B.2 - Define a Loss function and optimizer [3 pt]</a></li>
<li><a href="#Part-B3---Train-the-network-2-pt" title="Part B.3 - Train the network [2 pt]">Part B.3 - Train the network [2 pt]</a></li>
</ul>
</li>
<li><a href="#Part-C-Building-the-embedding-projector" title="Part C. Building the embedding projector">Part C. Building the embedding projector</a><ul class="nav">
<li><a href="#Part-C1---Build-an-embedding-projector-5-pt" title="Part C.1 - Build an embedding projector [5 pt]">Part C.1 - Build an embedding projector [5 pt]</a></li>
<li><a href="#Part-C2---Project-the-Embeddings-5-pt" title="Part C.2 - Project the Embeddings [5 pt]">Part C.2 - Project the Embeddings [5 pt]</a></li>
</ul>
</li>
<li><a href="#Part-D-Analysing-the-embeddings" title="Part D. Analysing the embeddings">Part D. Analysing the embeddings</a><ul class="nav">
<li><a href="#Part-D1---Analysing-the-embeddings-with-PCA---2-pts" title="Part D.1 - Analysing the embeddings with PCA - [2 pts]">Part D.1 - Analysing the embeddings with PCA - [2 pts]</a></li>
<li><a href="#Part-D2---Analysing-with-different-models-3-pts" title="Part D.2 - Analysing with different models [3 pts]">Part D.2 - Analysing with different models [3 pts]</a></li>
</ul>
</li>
<li><a href="#Additionals" title="Additionals">Additionals</a><ul class="nav">
<li><a href="#Fashion-MNIST" title="Fashion-MNIST">Fashion-MNIST</a></li>
</ul>
</li>
<li><a href="#References" title="References">References</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
            </ul>
        </div>
    </div>
    <div id="ui-toc-affix" class="ui-affix-toc ui-toc-dropdown unselectable hidden-print" data-spy="affix" style="top:17px;display:none;" null null>
        <div class="toc"><ul class="nav">
<li><a href="#Projecting-Your-Data" title="Projecting Your Data">Projecting Your Data</a><ul class="nav">
<li><a href="#Part-A-Data-exploration" title="Part A. Data exploration">Part A. Data exploration</a><ul class="nav">
<li><a href="#MNIST-Dataset" title="MNIST Dataset">MNIST Dataset</a></li>
<li><a href="#Part-A1---Load-Dataset-3-pt" title="Part A.1 - Load Dataset [3 pt]">Part A.1 - Load Dataset [3 pt]</a></li>
<li><a href="#Part-A2---Preview-the-Dataset-2-pt" title="Part A.2 - Preview the Dataset [2 pt]">Part A.2 - Preview the Dataset [2 pt]</a></li>
<li><a href="#Part-A3---Build-Your-Dataset-5-pt" title="Part A.3 - Build Your Dataset [5 pt]">Part A.3 - Build Your Dataset [5 pt]</a></li>
<li><a href="#Part-A4---Data-Augmentation-5-pt" title="Part A.4 - Data Augmentation [5 pt]">Part A.4 - Data Augmentation [5 pt]</a></li>
</ul>
</li>
<li><a href="#Part-B-Building-the-classifier" title="Part B. Building the classifier">Part B. Building the classifier</a><ul class="nav">
<li><a href="#Part-B1---Define-a-Convolutional-Neural-Network-5-pt" title="Part B.1 - Define a Convolutional Neural Network [5 pt]">Part B.1 - Define a Convolutional Neural Network [5 pt]</a></li>
<li><a href="#Part-B2---Define-a-Loss-function-and-optimizer-3-pt" title="Part B.2 - Define a Loss function and optimizer [3 pt]">Part B.2 - Define a Loss function and optimizer [3 pt]</a></li>
<li><a href="#Part-B3---Train-the-network-2-pt" title="Part B.3 - Train the network [2 pt]">Part B.3 - Train the network [2 pt]</a></li>
</ul>
</li>
<li><a href="#Part-C-Building-the-embedding-projector" title="Part C. Building the embedding projector">Part C. Building the embedding projector</a><ul class="nav">
<li><a href="#Part-C1---Build-an-embedding-projector-5-pt" title="Part C.1 - Build an embedding projector [5 pt]">Part C.1 - Build an embedding projector [5 pt]</a></li>
<li><a href="#Part-C2---Project-the-Embeddings-5-pt" title="Part C.2 - Project the Embeddings [5 pt]">Part C.2 - Project the Embeddings [5 pt]</a></li>
</ul>
</li>
<li><a href="#Part-D-Analysing-the-embeddings" title="Part D. Analysing the embeddings">Part D. Analysing the embeddings</a><ul class="nav">
<li><a href="#Part-D1---Analysing-the-embeddings-with-PCA---2-pts" title="Part D.1 - Analysing the embeddings with PCA - [2 pts]">Part D.1 - Analysing the embeddings with PCA - [2 pts]</a></li>
<li><a href="#Part-D2---Analysing-with-different-models-3-pts" title="Part D.2 - Analysing with different models [3 pts]">Part D.2 - Analysing with different models [3 pts]</a></li>
</ul>
</li>
<li><a href="#Additionals" title="Additionals">Additionals</a><ul class="nav">
<li><a href="#Fashion-MNIST" title="Fashion-MNIST">Fashion-MNIST</a></li>
</ul>
</li>
<li><a href="#References" title="References">References</a></li>
</ul>
</li>
</ul>
</div><div class="toc-menu"><a class="expand-toggle" href="#">Expand all</a><a class="back-to-top" href="#">Back to top</a><a class="go-to-bottom" href="#">Go to bottom</a></div>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.1.1/jquery.min.js" integrity="sha256-hVVnYaiADRTO2PzUGmuLJr8BLUSjGIZsDYGmIJLv2b8=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous" defer></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gist-embed/2.6.0/gist-embed.min.js" integrity="sha256-KyF2D6xPIJUW5sUDSs93vWyZm+1RzIpKCexxElmxl8g=" crossorigin="anonymous" defer></script>
    <script>
        var markdown = $(".markdown-body");
        //smooth all hash trigger scrolling
        function smoothHashScroll() {
            var hashElements = $("a[href^='#']").toArray();
            for (var i = 0; i < hashElements.length; i++) {
                var element = hashElements[i];
                var $element = $(element);
                var hash = element.hash;
                if (hash) {
                    $element.on('click', function (e) {
                        // store hash
                        var hash = this.hash;
                        if ($(hash).length <= 0) return;
                        // prevent default anchor click behavior
                        e.preventDefault();
                        // animate
                        $('body, html').stop(true, true).animate({
                            scrollTop: $(hash).offset().top
                        }, 100, "linear", function () {
                            // when done, add hash to url
                            // (default click behaviour)
                            window.location.hash = hash;
                        });
                    });
                }
            }
        }

        smoothHashScroll();
        var toc = $('.ui-toc');
        var tocAffix = $('.ui-affix-toc');
        var tocDropdown = $('.ui-toc-dropdown');
        //toc
        tocDropdown.click(function (e) {
            e.stopPropagation();
        });

        var enoughForAffixToc = true;

        function generateScrollspy() {
            $(document.body).scrollspy({
                target: ''
            });
            $(document.body).scrollspy('refresh');
            if (enoughForAffixToc) {
                toc.hide();
                tocAffix.show();
            } else {
                tocAffix.hide();
                toc.show();
            }
            $(document.body).scroll();
        }

        function windowResize() {
            //toc right
            var paddingRight = parseFloat(markdown.css('padding-right'));
            var right = ($(window).width() - (markdown.offset().left + markdown.outerWidth() - paddingRight));
            toc.css('right', right + 'px');
            //affix toc left
            var newbool;
            var rightMargin = (markdown.parent().outerWidth() - markdown.outerWidth()) / 2;
            //for ipad or wider device
            if (rightMargin >= 133) {
                newbool = true;
                var affixLeftMargin = (tocAffix.outerWidth() - tocAffix.width()) / 2;
                var left = markdown.offset().left + markdown.outerWidth() - affixLeftMargin;
                tocAffix.css('left', left + 'px');
            } else {
                newbool = false;
            }
            if (newbool != enoughForAffixToc) {
                enoughForAffixToc = newbool;
                generateScrollspy();
            }
        }
        $(window).resize(function () {
            windowResize();
        });
        $(document).ready(function () {
            windowResize();
            generateScrollspy();
        });

        //remove hash
        function removeHash() {
            window.location.hash = '';
        }

        var backtotop = $('.back-to-top');
        var gotobottom = $('.go-to-bottom');

        backtotop.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToTop)
                scrollToTop();
            removeHash();
        });
        gotobottom.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            if (scrollToBottom)
                scrollToBottom();
            removeHash();
        });

        var toggle = $('.expand-toggle');
        var tocExpand = false;

        checkExpandToggle();
        toggle.click(function (e) {
            e.preventDefault();
            e.stopPropagation();
            tocExpand = !tocExpand;
            checkExpandToggle();
        })

        function checkExpandToggle () {
            var toc = $('.ui-toc-dropdown .toc');
            var toggle = $('.expand-toggle');
            if (!tocExpand) {
                toc.removeClass('expand');
                toggle.text('Expand all');
            } else {
                toc.addClass('expand');
                toggle.text('Collapse all');
            }
        }

        function scrollToTop() {
            $('body, html').stop(true, true).animate({
                scrollTop: 0
            }, 100, "linear");
        }

        function scrollToBottom() {
            $('body, html').stop(true, true).animate({
                scrollTop: $(document.body)[0].scrollHeight
            }, 100, "linear");
        }
    </script>
</body>

</html>
